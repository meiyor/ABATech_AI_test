{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a223011",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries and sklearn Python packages for evaluation. This example include feature generation including\n",
    "## the feature from the 1) MinMaxScaler, 2) StandardScaler, 3) RobustScaler, 4) from the QuantileTransformer output\n",
    "## 5) the output from the KBinsDiscritizer, 6) 7 components of a PCA mapping, and 7) 7 components of TruncatedSVD map. \n",
    "## This will extend the original 22 features we have from the original data to new 124 features we will use for three di\n",
    "## different type of classifiers, such as logistic, SVM, and Neural Network\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.linear_model import LogisticRegression ## only use this if you want to do an extra feature selection from the new map of features\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE ## you can try TSNE if you consider\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "## read csv file it is faster\n",
    "dataframeObject = pd.DataFrame(pd.read_csv(str(sys.argv[1]))) ## add the name or the path of the .csv file transformed from the EDA\n",
    "\n",
    "## assigning the features names and putting them in a list\n",
    "features=list(dataframeObject.columns.values)\n",
    "\n",
    "for index in range(1,len(features)):\n",
    "    index_feature=features[index]\n",
    "    dataframeObject[[index_feature]].replace(np.nan,0)\n",
    "    data.append(dataframeObject[[index_feature]].to_numpy())\n",
    "\n",
    "data=np.squeeze(np.array(data))\n",
    "shape=np.shape(data)\n",
    "\n",
    "## convert all strings in integer values or dummy features similar to the EDA \n",
    "for count in range(0,shape[0]):\n",
    "  possibilities=[]\n",
    "  data_temp=[]\n",
    "  if isinstance(data[count,0],str):\n",
    "    for in_count in range(0,shape[1]):\n",
    "       if not(data[count,in_count] in possibilities):\n",
    "          possibilities.append(data[count,in_count])\n",
    "       index_val = int(possibilities.index(data[count,in_count]))\n",
    "       data_temp.append(index_val)\n",
    "    data[count,:]=np.array(data_temp)\n",
    "\n",
    "shape=np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d15cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data definition\n",
    "DATA=np.transpose(data[0:22,:])\n",
    "labels=data[22,:]\n",
    "\n",
    "shape=np.shape(DATA)\n",
    "##definition of crossvalidation using the KFold object from sklearn. Define the second argument for the k-folding evaluation\n",
    "kf = KFold(n_splits=int(sys.argv[2]))\n",
    "kf.get_n_splits(DATA)\n",
    "acc=np.zeros([int(sys.argv[2])])\n",
    "\n",
    "KFold(n_splits=int(sys.argv[2]), random_state=None, shuffle=False)\n",
    "\n",
    "## definition of the extra argument for the plotting in case it is 1\n",
    "if int(sys.argv[3])==1:\n",
    "    plt.ion()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "## crossvalidation execution the folding is defined  as an input parameter\n",
    "for i, (train_index, test_index) in enumerate(kf.split(DATA)):\n",
    "        print(f\":Fold {i}:\")\n",
    "        #print(f\"  Train: index={train_index}\")\n",
    "        #print(f\"  Test:  index={test_index}\")\n",
    "        transforms = list()\n",
    "        transforms.append(('mms', MinMaxScaler()))\n",
    "        transforms.append(('ss', StandardScaler()))\n",
    "        transforms.append(('rs', RobustScaler()))\n",
    "        transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
    "        transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
    "        transforms.append(('pca', PCA(n_components=7)))\n",
    "        transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
    "\n",
    "        # create the feature union\n",
    "        fu = FeatureUnion(transforms)\n",
    "        # define the feature selection only if you consider it to use it\n",
    "        #rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=15)\n",
    "        # define the model\n",
    "        model = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(100,10),learning_rate='adaptive',random_state=1)\n",
    "        steps = list()\n",
    "        steps.append(('fu', fu))\n",
    "        #steps.append(('rfe', rfe))\n",
    "        # normalize before feeding the model\n",
    "        scaler=MinMaxScaler()\n",
    "        steps.append(('sc',scaler))\n",
    "        steps.append(('m', model))\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        #train the model\n",
    "        DATA_train=DATA[train_index,:]\n",
    "        DATA_test=DATA[test_index,:]\n",
    "        #tsne_results =  tsne_pipeline.fit_transform(DATA_train) ## uncommented only if you consider it\n",
    "        pipeline.fit(DATA_train,labels[train_index].astype('int'))\n",
    "        predictions = pipeline.predict(DATA_test)\n",
    "        # calculate classification accuracy\n",
    "        acc[i] = accuracy_score(labels[test_index].astype('int'), predictions)\n",
    "        print(acc[i])\n",
    "        if int(sys.argv[3])==1:\n",
    "            RocCurveDisplay.from_estimator(pipeline, DATA_test, labels[test_index].astype('int'))\n",
    "            plt.draw()\n",
    "            plt.pause(0.001)\n",
    "            input(\"Press [enter] to continue.\")\n",
    "acc_mean=np.mean(acc)\n",
    "acc_std=np.std(acc)\n",
    "print(f\":accuracy:{acc_mean} +/- {acc_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
